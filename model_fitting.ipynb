{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc05dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "import cmdstanpy\n",
    "from cmdstanpy import CmdStanModel\n",
    "import pandas\n",
    "import scipy.stats\n",
    "import scipy.integrate\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15f22b1",
   "metadata": {},
   "source": [
    "Read in Data and plot each time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2294fad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pandas.read_excel('23_05_22 tet variable EML.xlsx', skiprows=7, sheet_name='Virus over cell area')\n",
    "\n",
    "t = df['Elapsed'].values\n",
    "\n",
    "data = {}\n",
    "\n",
    "percentages = [0, 20, 40, 60, 80, 100]\n",
    "\n",
    "for percentage in percentages:\n",
    "    x = df['SINV mCherry 10 MOI,{}% W(+) (1) 500K / well'.format(percentage)].values\n",
    "    xerr = df['SINV mCherry 10 MOI,{}% W(+) (1) 500K / well (Std Err Well)'.format(percentage)].values\n",
    "    data[percentage] = x\n",
    "\n",
    "fig = plt.figure(figsize=(10.5, 4))\n",
    "N = len(percentages)\n",
    "\n",
    "for i, percentage in enumerate(percentages):\n",
    "    ax = fig.add_subplot(2, N, i+1)\n",
    "    x = data[percentage]\n",
    "\n",
    "    ax.plot(t, x, color='k', zorder=-1)\n",
    "    p1 = ax.scatter(t, x, color='k', s=25)\n",
    "    p2 = ax.scatter(t, x, color='white', s=5)\n",
    "\n",
    "    ax.set_title('{}% W(+)'.format(percentage))\n",
    "\n",
    "    if i == N-1:\n",
    "        ax.legend(((p1, p2),), ['Data',])\n",
    "\n",
    "    if i == 0:\n",
    "        ax.set_ylabel('Virus over cell area')\n",
    "\n",
    "    ax = fig.add_subplot(2, N, i+1+N)\n",
    "\n",
    "    p1, = ax.plot(t, x, color='k')\n",
    "    p2 = ax.fill_between(t, x-xerr, x+xerr, alpha=0.25, color='k')\n",
    "    \n",
    "    ax.set_xlabel('Time (hours)')\n",
    "\n",
    "    if i == N-1:\n",
    "        ax.legend(((p1, p2),), [r'Data $\\pm$ Std Err',])\n",
    "\n",
    "    if i == 0:\n",
    "        ax.set_ylabel('Virus over cell area')\n",
    "\n",
    "\n",
    "fig.set_tight_layout(True)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0ec443",
   "metadata": {},
   "source": [
    "Run prior predictive checks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf26d0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prior predictive\n",
    "\n",
    "num_prior_samples = 10000\n",
    "\n",
    "all_solns_compound = []\n",
    "\n",
    "for _ in range(num_prior_samples):\n",
    "    theta = scipy.stats.truncnorm.rvs(0, np.inf, loc=0, scale=1, size=8)\n",
    "    area_ratio = random.uniform(0.8, 1.0)\n",
    "    V_0 = scipy.stats.truncnorm.rvs(0.01, 10000, loc=0, scale=0.1)\n",
    "    colonized_prop = random.uniform(0.1, 1.0)\n",
    "    \n",
    "    full_soln = []\n",
    "    for i in range(6):\n",
    "\n",
    "        y0 = [\n",
    "            (1.0 - colonized_prop * 0.2 * i) * area_ratio,\n",
    "            0.0,\n",
    "            V_0,\n",
    "            0.0,\n",
    "            0.0,\n",
    "        ]\n",
    "\n",
    "        def f(t, y):\n",
    "            T = y[0]\n",
    "            I = y[1]\n",
    "            V = y[2]\n",
    "            P = y[3]\n",
    "            C = y[4]\n",
    "\n",
    "            dydt = [0, 0, 0, 0, 0]\n",
    "\n",
    "            dydt[0] = -theta[0] * T * V - theta[3] * C * T\n",
    "            dydt[1] = theta[0] * T * V - theta[3] * C * I\n",
    "            dydt[2] = theta[1] * I - theta[2] * C * V\n",
    "            dydt[3] = theta[3] * C * T + theta[3] * C * I\n",
    "            dydt[4] = theta[4] * 0.2 * i - theta[5] * C * T - theta[5] * C * I - theta[6] * C - theta[7] * C * V\n",
    "\n",
    "            return dydt\n",
    "\n",
    "        sol = scipy.integrate.solve_ivp(\n",
    "            f,\n",
    "            (0, 148),\n",
    "            y0,\n",
    "            t_eval=t,\n",
    "        ).y\n",
    "\n",
    "        full_soln.append(sol)\n",
    "\n",
    "    all_solns_compound.append(full_soln)\n",
    "\n",
    "all_solns_compound = np.asarray(all_solns_compound)\n",
    "\n",
    "\n",
    "# Prior predictive Extended Model\n",
    "all_solns_extended = []\n",
    "\n",
    "for _ in range(num_prior_samples):\n",
    "\n",
    "    theta = scipy.stats.truncnorm.rvs(0, np.inf, loc=0, scale=1, size=10)\n",
    "    area_ratio = random.uniform(0.8, 1.0)\n",
    "    V_0 = scipy.stats.truncnorm.rvs(0.01, 10000, loc=0, scale=0.1)\n",
    "    colonized_prop = random.uniform(0.1, 1.0)\n",
    "\n",
    "    full_soln = []\n",
    "    for i in range(6):\n",
    "\n",
    "        y0 = [\n",
    "            (1.0 - colonized_prop * 0.2 * i) * area_ratio,\n",
    "            0.0,\n",
    "            V_0,\n",
    "            0.0,\n",
    "        ]\n",
    "\n",
    "        def f(t, y):\n",
    "            T = y[0]\n",
    "            I = y[1]\n",
    "            V = y[2]\n",
    "            E = y[3]\n",
    "\n",
    "            dydt = [0, 0, 0, 0,]\n",
    "\n",
    "            beta = theta[0]\n",
    "            p = theta[1]\n",
    "            L = theta[2]\n",
    "            e = theta[3]\n",
    "            s = theta[4]\n",
    "            A1 = theta[5]\n",
    "            A2 = theta[6]\n",
    "            l1 = theta[7]\n",
    "            l2 = theta[8]\n",
    "            tstar = theta[9]\n",
    "\n",
    "            dydt[0] = -beta * T * V / (L + V)\n",
    "            dydt[1] = e * E\n",
    "\n",
    "            if t <= tstar:\n",
    "                F = A1 * np.exp(l1 * t)\n",
    "            else:\n",
    "                F = A2 * np.exp(-l2 * t)\n",
    "            dydt[2] = p * I / (1.0 + s * F)\n",
    "\n",
    "            dydt[3] = beta * T * V / (L + V) - e * E\n",
    "\n",
    "            return dydt\n",
    "\n",
    "        sol = scipy.integrate.solve_ivp(\n",
    "            f,\n",
    "            (0, 148),\n",
    "            y0,\n",
    "            t_eval=t,\n",
    "        ).y\n",
    "\n",
    "        full_soln.append(sol)\n",
    "\n",
    "    all_solns_extended.append(full_soln)\n",
    "\n",
    "all_solns_extended = np.asarray(all_solns_extended)\n",
    "\n",
    "\n",
    "# Prior predictive Basic Model\n",
    "all_solns_basic = []\n",
    "\n",
    "for _ in range(num_prior_samples):\n",
    "\n",
    "    theta = scipy.stats.truncnorm.rvs(0, np.inf, loc=0, scale=1, size=2)\n",
    "    area_ratio = random.uniform(0.8, 1.0)\n",
    "    V_0 = scipy.stats.truncnorm.rvs(0.01, 10000, loc=0, scale=0.1)\n",
    "    colonized_prop = random.uniform(0.1, 1.0)\n",
    "\n",
    "    full_soln = []\n",
    "    for i in range(6):\n",
    "\n",
    "        y0 = [\n",
    "            (1.0 - colonized_prop * 0.2 * i) * area_ratio,\n",
    "            0.0,\n",
    "            V_0,\n",
    "        ]\n",
    "\n",
    "        def f(t, y):\n",
    "            T = y[0]\n",
    "            I = y[1]\n",
    "            V = y[2]\n",
    "\n",
    "            dydt = [0, 0, 0,]\n",
    "\n",
    "            beta = theta[0]\n",
    "            p = theta[1]\n",
    "\n",
    "            dydt[0] = -beta * T * V\n",
    "            dydt[1] = beta * T * V\n",
    "            dydt[2] = p * I\n",
    "            return dydt\n",
    "\n",
    "        sol = scipy.integrate.solve_ivp(\n",
    "            f,\n",
    "            (0, 148),\n",
    "            y0,\n",
    "            t_eval=t,\n",
    "        ).y\n",
    "\n",
    "        full_soln.append(sol)\n",
    "\n",
    "    all_solns_basic.append(full_soln)\n",
    "\n",
    "all_solns_basic = np.asarray(all_solns_basic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e20619",
   "metadata": {},
   "source": [
    "Plot prior predictive results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9eb47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 6))\n",
    "\n",
    "i = 1\n",
    "style = 0\n",
    "ax = None\n",
    "\n",
    "model_names = ['Compound Model', 'Basic Comparator', 'Extended Comparator']\n",
    "\n",
    "for model in [1, 2, 3]:\n",
    "\n",
    "    if model == 1:\n",
    "        all_solns = all_solns_compound\n",
    "    elif model == 2:\n",
    "        all_solns = all_solns_basic\n",
    "    elif model == 3:\n",
    "        all_solns = all_solns_extended\n",
    "\n",
    "    for j in range(6):\n",
    "        ax = fig.add_subplot(3, 6, j + 1 + 6 * (model - 1), sharey=ax, sharex=ax)\n",
    "\n",
    "        if style == 0:\n",
    "            mid = np.median(all_solns[:, j, i, :], axis=0)\n",
    "            upper = np.percentile(all_solns[:, j, i, :], 99.5, axis=0)\n",
    "            lower = np.percentile(all_solns[:, j, i, :], 0.5, axis=0)\n",
    "            l1, = ax.plot(t, 100 * mid)\n",
    "            l2 = ax.fill_between(t, 100 * lower, 100 * upper, alpha=0.25)\n",
    "    \n",
    "        elif style == 1:\n",
    "            for traj in all_solns[::50, j, i, :]:\n",
    "                l1, = ax.plot(t, 100 * traj, alpha=0.2, color='tab:blue')\n",
    "                l2 = l1\n",
    "\n",
    "        if model == 3:\n",
    "            ax.set_xlabel('Time (hours)')\n",
    "        if j == 0:\n",
    "            ax.set_ylabel('I\\n({})'.format(model_names[model-1]))\n",
    "\n",
    "        if model == 1:\n",
    "            ax.set_title('{}% W'.format(j * 20))\n",
    "\n",
    "        x = data[20 * j]\n",
    "        l3, = ax.plot(t, x, color='k', zorder=100000, lw=2, ls='--', label='Data')\n",
    "\n",
    "        if model == 1 and j == 5:\n",
    "            ax.legend(((l1, l2,), l3,), ['Prior (99%)', 'Data'], loc='upper right')\n",
    "\n",
    "\n",
    "fig.set_tight_layout(True)\n",
    "\n",
    "plt.savefig('prior_all_models.pdf')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f42ee6",
   "metadata": {},
   "source": [
    "Run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e77d31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CmdStanModel(stan_file='model.stan', cpp_options={'STAN_THREADS':'true'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cae64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_prior(n_theta, n_sigma):\n",
    "    \"\"\"Generate a sample from the prior.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    n_theta : int\n",
    "        Dimension of theta parameter vector\n",
    "    n_sigma : int\n",
    "        Dimension of sigma noise parameter vector\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Parameter values sampled from the prior distribution\n",
    "    \"\"\"\n",
    "    theta = []\n",
    "    area_ratio = []\n",
    "    V_0 = []\n",
    "    sigma = []\n",
    "\n",
    "    for _ in range(1):\n",
    "        theta.append(scipy.stats.truncnorm.rvs(0, 1000, loc=0, scale=1, size=n_theta))\n",
    "        area_ratio.append(scipy.stats.uniform.rvs(loc=0.8, scale=0.2))\n",
    "        V_0.append(scipy.stats.uniform.rvs(loc=0.02, scale=0.08, size=1))\n",
    "        sigma.append(scipy.stats.truncnorm.rvs(0, 1000, loc=0, scale=0.01, size=n_sigma))\n",
    "\n",
    "    return {'theta': theta[0], 'area_ratio': area_ratio[0], 'V_0': V_0[0][0], 'sigma': sigma[0],}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19122d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_types = [1, 2, 3]\n",
    "num_repeats = 20\n",
    "\n",
    "results = {}\n",
    "\n",
    "for model_type in model_types:\n",
    "\n",
    "    stan_data = {\n",
    "        'T': len(t),\n",
    "        'N': 6,\n",
    "        'v': np.asarray([data[0], data[20], data[40], data[60], data[80], data[100],]).T / 100.0,\n",
    "        'ts': t,\n",
    "        'model_type': model_type,\n",
    "        'use_priors': 1,\n",
    "    }\n",
    "\n",
    "    cmdstanpy.write_stan_json('data.json', stan_data)\n",
    "\n",
    "    best_fit = None\n",
    "    best_value = -np.inf\n",
    "\n",
    "    for _ in range(num_repeats):\n",
    "        try:\n",
    "            fit = model.optimize(data='data.json', inits=sample_prior(8 if model_type == 1 else 10 if model_type == 3 else 2, stan_data['N']))\n",
    "            lp = fit.optimized_params_pd['lp__'].values[0]\n",
    "        except RuntimeError as e:\n",
    "            print(e)\n",
    "            lp = -np.inf\n",
    "        if lp > best_value:\n",
    "            best_fit = fit\n",
    "            best_value = lp\n",
    "\n",
    "    results[model_type] = [best_fit, best_value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57355d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_types = [1, 2, 3]\n",
    "num_repeats = 20\n",
    "\n",
    "results_mle = {}\n",
    "\n",
    "for model_type in model_types:\n",
    "\n",
    "    stan_data = {\n",
    "        'T': len(t),\n",
    "        'N': 6,\n",
    "        'v': np.asarray([data[0], data[20], data[40], data[60], data[80], data[100],]).T / 100.0,\n",
    "        'ts': t,\n",
    "        'model_type': model_type,\n",
    "        'use_priors': 0,\n",
    "    }\n",
    "\n",
    "    cmdstanpy.write_stan_json('data.json', stan_data)\n",
    "\n",
    "    best_fit = None\n",
    "    best_value = -np.inf\n",
    "\n",
    "    for _ in range(num_repeats):\n",
    "        try:\n",
    "            init = {'theta': results[model_type][0].theta, 'colonized_prop': results[model_type][0].colonized_prop, 'area_ratio': results[model_type][0].area_ratio, 'V_0': results[model_type][0].V_0, 'sigma': results[model_type][0].sigma}\n",
    "            fit = model.optimize(data='data.json', inits=init)\n",
    "            lp = fit.optimized_params_pd['lp__'].values[0]\n",
    "        except RuntimeError as e:\n",
    "            print(e)\n",
    "            lp = -np.inf\n",
    "        if lp > best_value:\n",
    "            best_fit = fit\n",
    "            best_value = lp\n",
    "\n",
    "    results_mle[model_type] = [best_fit, best_value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f75eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAE(fit, data):\n",
    "    abs_errors = []\n",
    "    for i in range(5):\n",
    "        y = fit.simulated_y[:, 1, i]\n",
    "        abs_errors += list(100.0 * np.abs(y - data.T[i]))\n",
    "    return np.mean(abs_errors)\n",
    "\n",
    "model_num_params = {1: 17, 2: 11, 3: 19}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020ef03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute metrics of comparison\n",
    "models = [1, 2, 3]\n",
    "\n",
    "model_names = ['Protective Compound', 'Basic Comparator', 'Extended Comparator']\n",
    "mlp = [results[model_type][1] for model_type in models]\n",
    "mll = [results_mle[model_type][0].log_likelihood for model_type in models]\n",
    "aic = [2 * model_num_params[model_type] - 2 * results_mle[model_type][0].log_likelihood for model_type in models]\n",
    "mae = [MAE(results[model_type][0], stan_data['v']) for model_type in models]\n",
    "\n",
    "\n",
    "df = pandas.DataFrame(\n",
    "    {\n",
    "     'Model': model_names,\n",
    "     'Maximum Log Posterior': mlp,\n",
    "      'Mean Absolute Error': mae,\n",
    "     'Maximum Log Likelihood': mll,\n",
    "     'AIC': aic,\n",
    "    }\n",
    "    )\n",
    "\n",
    "df.to_excel('comparison_statistics.xlsx', index=False, float_format=\"%.3f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260ee9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "lss = ['o-', 'd-', 'v-', '^-', 'h-']\n",
    "lsss = ['-', '-.', '--', ':', '-']\n",
    "colors = [(252, 60, 69), (203, 112, 25), (141, 148, 25), (81, 168, 71), (25, 177, 134), (23, 176, 192)]\n",
    "colors = [[x/255 for x in y] for y in colors]\n",
    "\n",
    "labels = []\n",
    "data_labels = []\n",
    "names = []\n",
    "\n",
    "T_ax = None\n",
    "\n",
    "datas = [0, 20, 40, 60, 80]\n",
    "\n",
    "fig = plt.figure(figsize=(8, 3.5))\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "\n",
    "for _i, i in enumerate([1, 2, 3, 4, 5]):\n",
    "\n",
    "    x = data[datas[_i]]\n",
    "    p2 = ax.scatter(t, x, s=6, marker=lss[i-1][0], color=colors[i-1])\n",
    "\n",
    "    fit = results[1][0]\n",
    "    p3, = ax.plot(t, 100 * fit.simulated_y[:, 1, _i], zorder=5, lw=2, color=colors[_i])\n",
    "\n",
    "    labels.append((p3,))\n",
    "    names.append('{}% W(+)'.format(datas[_i]))\n",
    "    data_labels.append((p2,))\n",
    "\n",
    "\n",
    "ax.set_xlabel('Time (Hours)')\n",
    "ax.set_ylabel('Virus over cell area (%)')\n",
    "\n",
    "s0 = ax.scatter([1, ], [110,], marker='$/$', color='k', label='Data', s=100)\n",
    "ax.set_ylim(None, 95)\n",
    "\n",
    "ax.legend(data_labels + [s0,] * 5 + labels, [''] * 10 + names, title='Data / Fit                  ', loc='center left', bbox_to_anchor=(1, 0.75), ncol=3, handlelength=1.5, borderpad=0.7, handletextpad=1.25, columnspacing=-1.5)\n",
    "\n",
    "fig.set_tight_layout(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c3cbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fits = pandas.DataFrame(\n",
    "    {\n",
    "        'Time': t,\n",
    "        '0% W': 100 * results[1][0].simulated_y[:, 1, 0],\n",
    "        '20% W': 100 * results[1][0].simulated_y[:, 1, 1],\n",
    "        '40% W': 100 * results[1][0].simulated_y[:, 1, 2],\n",
    "        '60% W': 100 * results[1][0].simulated_y[:, 1, 3],\n",
    "        '80% W': 100 * results[1][0].simulated_y[:, 1, 4],\n",
    "        '100% W': 100 * results[1][0].simulated_y[:, 1, 5],\n",
    "    }\n",
    ")\n",
    "df_fits.to_excel('fit_compound.xlsx', index=False, float_format=\"%.3f\")\n",
    "\n",
    "\n",
    "df_fits = pandas.DataFrame(\n",
    "    {\n",
    "        'Time': t,\n",
    "        '0% W': 100 * results[2][0].simulated_y[:, 1, 0],\n",
    "        '20% W': 100 * results[2][0].simulated_y[:, 1, 1],\n",
    "        '40% W': 100 * results[2][0].simulated_y[:, 1, 2],\n",
    "        '60% W': 100 * results[2][0].simulated_y[:, 1, 3],\n",
    "        '80% W': 100 * results[2][0].simulated_y[:, 1, 4],\n",
    "        '100% W': 100 * results[2][0].simulated_y[:, 1, 5],\n",
    "    }\n",
    ")\n",
    "df_fits.to_excel('fit_basic_comparator.xlsx', index=False, float_format=\"%.3f\")\n",
    "\n",
    "\n",
    "df_fits = pandas.DataFrame(\n",
    "    {\n",
    "        'Time': t,\n",
    "        '0% W': 100 * results[3][0].simulated_y[:, 1, 0],\n",
    "        '20% W': 100 * results[3][0].simulated_y[:, 1, 1],\n",
    "        '40% W': 100 * results[3][0].simulated_y[:, 1, 2],\n",
    "        '60% W': 100 * results[3][0].simulated_y[:, 1, 3],\n",
    "        '80% W': 100 * results[3][0].simulated_y[:, 1, 4],\n",
    "        '100% W': 100 * results[3][0].simulated_y[:, 1, 5],\n",
    "    }\n",
    ")\n",
    "df_fits.to_excel('fit_extended_comparator.xlsx', index=False, float_format=\"%.3f\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stan_env2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
